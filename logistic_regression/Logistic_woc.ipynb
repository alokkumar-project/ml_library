{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c23c8686-4c1e-4c1c-9cc9-8020886c0f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def macro_f1(y_pre,y_test):\n",
    "    f1_scores =[]\n",
    "    unique_value=np.unique(y_test)\n",
    "    for value in unique_value:\n",
    "        true_pos = np.sum((y_pre==value)&(y_test==value))\n",
    "        false_pos = np.sum((y_pre==value)&(y_test!=value))\n",
    "        false_neg = np.sum((y_pre!=value)&(y_test==value))\n",
    "        true_neg =np.sum((y_pre!=value)&(y_test!=value))\n",
    "        recall = true_pos/(true_pos+false_neg)\n",
    "        precision = true_pos/(true_pos+false_pos)\n",
    "        if(recall+precision==0):\n",
    "            f1_scores.append(0)\n",
    "            continue\n",
    "        f1 = 2*(recall*precision)/(recall+precision)\n",
    "        f1_scores.append(f1)\n",
    "    return np.mean(f1_scores)\n",
    "        \n",
    "  \n",
    "def f1_score(y_pre,y_test):\n",
    "    data = pd.DataFrame({\n",
    "        'predicted':y_pre,\n",
    "        'actual':y_test,\n",
    "    })\n",
    "    true_pos = data[(data['predicted']==1)& (data['actual']==1)].shape[0]\n",
    "    true_neg =  data[(data['predicted']==0)& (data['actual']==0)].shape[0]\n",
    "    false_pos =  data[(data['predicted']==1)&(data['actual']==0)].shape[0]\n",
    "    false_neg =  data[(data['predicted']==0)& (data['actual']==1)].shape[0]\n",
    "\n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    f1_score = 2*(precision*recall)/(precision+recall)\n",
    "    return f1_score\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -500, 500)\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "class Logistic_Regression:\n",
    "    def __init__(self,epoch=1000,rate=0.01,):\n",
    "        self.rate = rate\n",
    "        self.numb = epoch\n",
    "        self.class_index={}\n",
    "    def fit(self,x_train,y_train):\n",
    "        y_train = np.array(y_train)\n",
    "        self.output = len(np.unique(y_train))\n",
    "        if(self.output>2):\n",
    "            self.activation=self.softmax\n",
    "            y_train = self.one_hot_coding(y_train)\n",
    "            self.coffei = np.ones((x_train.shape[1]+1, self.output))\n",
    "        else:\n",
    "            self.activation=sigmoid\n",
    "            self.coffei = np.ones(x_train.shape[1]+1)\n",
    "        x_train = np.array(x_train)\n",
    "        x_train = np.insert(x_train,0,1,axis=1)\n",
    "        \n",
    "        for i in range(self.numb):\n",
    "            y_hat = self.activation(np.dot(x_train,self.coffei))\n",
    "            self.coffei = self.coffei + np.dot(x_train.T,(y_train-y_hat))*self.rate/x_train.shape[0]\n",
    "    def predict(self,x_test,value=0.5):\n",
    "        x_test = np.array(x_test)\n",
    "        x_test = np.insert(x_test,0,1,axis=1)\n",
    "        results = self.activation(np.dot(x_test,self.coffei))\n",
    "        \n",
    "        final_result = []\n",
    "        if(self.activation==sigmoid):\n",
    "            for i in range(results.shape[0]):\n",
    "                if(results[i]>=value):\n",
    "                    final_result.append(1)\n",
    "                else:\n",
    "                    final_result.append(0)\n",
    "        else:\n",
    "            if(self.activation==self.softmax):\n",
    "            \n",
    "                result= np.argmax(results,axis=1)\n",
    "                \n",
    "                reverse_dic = {}\n",
    "            \n",
    "                for key,value in self.class_index.items():\n",
    "                    reverse_dic[value]=key\n",
    "                \n",
    "                \n",
    "            \n",
    "                for i in result:\n",
    "                    final_result.append(reverse_dic[i])\n",
    "                \n",
    "            return final_result\n",
    "            \n",
    "            \n",
    "            \n",
    "        return final_result\n",
    "    def softmax(self,z):\n",
    "        z=z-np.max(z,axis=1,keepdims=True)\n",
    "        exp_z=np.exp(z)\n",
    "        return exp_z/(np.sum(exp_z,axis=1,keepdims=True))\n",
    "    def one_hot_coding(self,y_test):\n",
    "        y_test = np.array(y_test)\n",
    "        \n",
    "        pos = 0\n",
    "        for i in y_test:\n",
    "            if i not in self.class_index:\n",
    "                self.class_index[i]=pos\n",
    "                pos = pos+1\n",
    "        target = []\n",
    "        for i in y_test:\n",
    "            new = []\n",
    "            for j in range(self.output):\n",
    "                if(j==self.class_index[i]):\n",
    "                    new.append(1)\n",
    "                else:\n",
    "                    new.append(0)\n",
    "            target.append(new)\n",
    "        return np.array(target)\n",
    "        \n",
    "        \n",
    "\n",
    "class Bag_logistic:\n",
    "    def __init__(self,percent,lg_count):\n",
    "        self.lg_count = lg_count\n",
    "        self.percent = percent\n",
    "    def bag(self,dataset):\n",
    "        self.dataset = dataset\n",
    "        sample_datasets = []\n",
    "        \n",
    "        for i in range(self.lg_count):\n",
    "            datasets = self.dataset.sample(int(dataset.shape[0]*self.percent),random_state=i)\n",
    "            sample_datasets.append(datasets)\n",
    "\n",
    "        self.sample_datasets_target = []\n",
    "        for i in range(self.lg_count):\n",
    "            target_column = sample_datasets[i]['target']\n",
    "            sample_datasets[i] = sample_datasets[i].drop(columns=['target'])\n",
    "            self.sample_datasets_target.append(target_column)\n",
    "\n",
    "        self.lg_object = []\n",
    "        for i in range(self.lg_count):\n",
    "            lgobject = Logistic_Regression(1000,0.01)\n",
    "            lgobject.fit(sample_datasets[i],self.sample_datasets_target[i])\n",
    "            self.lg_object.append(lgobject)\n",
    "        print(\"Trained Successfully\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def bag_predict(self,test_dataset,value):\n",
    "        final_output = []\n",
    "        for i in range(self.lg_count):\n",
    "            result = self.lg_object[i].predict(test_dataset,value)\n",
    "            final_output.append(result)\n",
    "        final_output = np.array(final_output)\n",
    "        votes = np.sum(final_output,axis=0)\n",
    "        majority = (votes >= (self.lg_count // 2 + 1)).astype(int)\n",
    "        return majority\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61fc3ae6-dbf5-4e6c-8fa6-2947669311de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_test_split:\n",
    "    def __init__(self,dataset,test_size=0.2,random=1,target='target'):\n",
    "        self.target = target\n",
    "        self.random_state=random\n",
    "        self.test_size=test_size\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        self.row = self.dataset.shape[0]\n",
    "\n",
    "\n",
    "    def split(self):\n",
    "        \n",
    "        np.random.seed(self.random_state)\n",
    "        row_count = int(self.row*self.test_size)\n",
    "        value = np.arange(0,self.row)\n",
    "        row_no = np.random.choice(value,replace=False,size=row_count)\n",
    "        \n",
    "\n",
    "        test_dataset = self.dataset.iloc[row_no]\n",
    "        x_test = test_dataset.drop(columns=[self.target])\n",
    "        y_test = test_dataset[self.target]\n",
    "\n",
    "        remaining_row=[]\n",
    "        for i in range(self.row):\n",
    "            if i not in row_no:\n",
    "                remaining_row.append(i)\n",
    "        train_dataset = self.dataset.iloc[remaining_row]\n",
    "        x_train = train_dataset.drop(columns=[self.target])\n",
    "        y_train = train_dataset[self.target]\n",
    "        \n",
    "        return x_train,x_test,y_train,y_test\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8298e07-ac5a-4226-a32d-428f261286d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Scaler:\n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        \n",
    "    def scale(self,dataset):\n",
    "        \n",
    "        self.mean = dataset.mean()\n",
    "        self.std = dataset.std()\n",
    "        \n",
    "    \n",
    "    def transform(self,dataset):\n",
    "        new_dataset = (dataset-self.mean)/(self.std)\n",
    "        return new_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c96bcaf3-ecc0-4790-ad87-9ab41f71d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_binary.csv')\n",
    "t = Train_test_split(data,target='label')\n",
    "x_train,x_test,y_train,y_test = t.split()\n",
    "\n",
    "\n",
    "s = Scaler()\n",
    "s.scale(x_train)\n",
    "x_train = s.transform(x_train)\n",
    "x_test = s.transform(x_test)\n",
    "x_train['target']=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13b53f24-19d6-4ebb-82ca-377b7b96f082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Successfully\n"
     ]
    }
   ],
   "source": [
    "b = Bag_logistic(0.7,50)\n",
    "b.bag(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aadf1c9-900c-4611-962e-d848180d914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = b.bag_predict(x_test,.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bad625d-3a83-47c5-a57d-a35ed15f1c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "score=f1_score(out,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b8c9366-0168-4580-b501-928a3f65a391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.949025974025974"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daa5bebb-b0de-490c-8c68-1691756cdf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_binary.csv')\n",
    "test_data=s.transform(data)\n",
    "pre_value = b.bag_predict(test_data,.85)\n",
    "id_ = np.arange(test_data.shape[0])\n",
    "submit = pd.DataFrame({\n",
    "    'id':id_,\n",
    "    'predicted_value' :pre_value\n",
    "})\n",
    "submit.to_csv('Binary_Submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5fe0015-c82e-4610-a664-dfb53895e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_multi_class_new.csv')\n",
    "t = Train_test_split(data,target='target')\n",
    "x_train,x_test,y_train,y_test = t.split()\n",
    "\n",
    "\n",
    "s = Scaler()\n",
    "s.scale(x_train)\n",
    "x_train = s.transform(x_train)\n",
    "x_test = s.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f31093ce-e720-4dfb-baea-6f5bf1317c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = Logistic_Regression(epoch=13000,rate=0.5)\n",
    "lg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1866b852-e1f7-4cf0-b61c-11e7c1853230",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre=lg.predict(x_test,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "409b4de2-21a2-48a3-bd47-9bee13488ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = macro_f1(y_pre,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5ae5c23-3273-44dc-b898-1f472946eeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5867394968830728)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4de26ad7-092b-46c3-9283-9f6cc7874630",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_multi_class.csv')\n",
    "test_data=s.transform(test_data)\n",
    "pre_value = lg.predict(test_data,.5)\n",
    "id_ = np.arange(test_data.shape[0])\n",
    "submit = pd.DataFrame({\n",
    "    'id':id_,\n",
    "    'predicted_value' :pre_value\n",
    "})\n",
    "submit.to_csv('multi-class_Submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f96caa-781e-4491-aba5-c8a546174209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
