{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70eb184b-ce23-43c1-b1c9-23b856157c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:129: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<>:129: SyntaxWarning: invalid escape sequence '\\_'\n",
      "/var/folders/qx/m587h9hn4155cbn53_ttrdhc0000gn/T/ipykernel_2916/348759918.py:129: SyntaxWarning: invalid escape sequence '\\_'\n",
      "  (\\__/)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Polynomial_Regression:\n",
    "    def __init__(self, degree=3, num=1000):\n",
    "        self.degree = degree\n",
    "        self.num = num\n",
    "        self.scaler = Scaler()\n",
    "\n",
    "    def _poly_features(self, X):\n",
    "        base = X.copy()\n",
    "        out = X.copy()\n",
    "\n",
    "        for d in range(2, self.degree + 1):\n",
    "            for col in base.columns:\n",
    "                out[f\"{col}^{d}\"] = base[col] ** d\n",
    "        return out\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_poly = self._poly_features(X)\n",
    "\n",
    "        self.scaler.scale(X_poly)\n",
    "        X_poly = self.scaler.transform(X_poly)\n",
    "\n",
    "        lr = Linear_Regression(self.num)\n",
    "        self.intercept, self.coef = lr.fit(X_poly, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_poly = self._poly_features(X)\n",
    "        X_poly = self.scaler.transform(X_poly)\n",
    "        return self.intercept + np.dot(X_poly.values, self.coef)\n",
    "\n",
    "class Linear_Regression:\n",
    "    def __init__(self,numb=1000,learning_rate=0.01):\n",
    "        self.numb = numb\n",
    "        self.rate = learning_rate\n",
    "    def fit(self,x_train,y_train):\n",
    "        self.x_train = np.array(x_train)\n",
    "        self.y_train = np.array(y_train)\n",
    "        self.coffe = np.ones(self.x_train.shape[1])\n",
    "        self.inter = 0\n",
    "        self.v_inter = 0\n",
    "        self.v_coffe = np.zeros(self.x_train.shape[1])\n",
    "        beta = 0.9\n",
    "        \n",
    "        for i in range(self.numb):\n",
    "            y_hat = np.dot(self.x_train,self.coffe) + self.inter\n",
    "            intercept_derivative = (-2/(self.x_train.shape[0]))*(np.sum(self.y_train-y_hat))\n",
    "            cofficenet_derivative = (-2/(self.x_train.shape[0]))*(np.dot((self.x_train.T),(self.y_train-y_hat)))\n",
    "\n",
    "            self.v_coffe = beta * self.v_coffe + cofficenet_derivative\n",
    "            self.v_inter = beta * self.v_inter + intercept_derivative\n",
    "\n",
    "            \n",
    "            self.inter = self.inter - self.rate*self.v_inter\n",
    "            self.coffe = self.coffe - self.rate*self.v_coffe\n",
    "        self.y_hat_pred = np.dot(self.x_train,self.coffe)+self.inter\n",
    "        return self.inter, self.coffe\n",
    "\n",
    "\n",
    "    def predict(self,x_test):\n",
    "        x_test = np.array(x_test)\n",
    "        self.predict_result = self.inter + np.dot(x_test,self.coffe)\n",
    "        self.x_test = x_test\n",
    "        return self.predict_result\n",
    "    \n",
    "    \n",
    "    def r2_score(self,y_pre,y_test):\n",
    "        \n",
    "        y_mean = np.mean(y_test)\n",
    "\n",
    "        ss_r = np.sum((y_test - y_pre)**2)\n",
    "        ss_m = np.sum((y_test - y_mean)**2)\n",
    "        \n",
    "        self.r2 = 1-ss_r/ss_m\n",
    "\n",
    "        return self.r2\n",
    "        \n",
    "    def adjusted_r2_score(self):\n",
    "        row = self.x_train.shape[0]\n",
    "        col = self.x_train.shape[1]\n",
    "        self.adjusted = 1-((1-self.r2)*(row-1)/(row-1-col))\n",
    "        return self.adjusted\n",
    "\n",
    "class Scaler:\n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        \n",
    "    def scale(self,dataset):\n",
    "        \n",
    "        self.mean = dataset.mean()\n",
    "        self.std = dataset.std()\n",
    "        \n",
    "    \n",
    "    def transform(self,dataset):\n",
    "        new_dataset = (dataset-self.mean)/(self.std)\n",
    "        return new_dataset\n",
    "    \n",
    "class Bagging_Linear:\n",
    "    def __init__(self,percent=0.7,lr_count=5,epoch=1000,rate=0.01):\n",
    "        self.epoch=epoch\n",
    "        self.rate = rate\n",
    "        self.count = lr_count\n",
    "        self.percent = percent\n",
    "    def fit(self,dataset):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "\n",
    "        bag_item = []\n",
    "\n",
    "        for i in range(self.count):\n",
    "            datasets = self.dataset.sample(int(dataset.shape[0]*(self.percent)),random_state=i,replace=True)\n",
    "            bag_item.append(datasets)\n",
    "\n",
    "        bag_item_target = []\n",
    "        for i in range(self.count):\n",
    "            target_item = bag_item[i]['target']\n",
    "            bag_item[i]= bag_item[i].drop(columns=['target'])\n",
    "            bag_item_target.append(target_item)\n",
    "\n",
    "        self.lr_object = []\n",
    "        for i in range(self.count):\n",
    "            lrobject = Linear_Regression(numb=self.epoch,learning_rate=self.rate)\n",
    "            lrobject.fit(bag_item[i],bag_item_target[i])\n",
    "            self.lr_object.append(lrobject)\n",
    "        print(\"\"\"\n",
    "        (\\__/)\n",
    "        (^_ ^)\n",
    "        (>Training Completed\n",
    "        \"\"\")\n",
    "            \n",
    "    def bag_predict(self,x_test):\n",
    "        \"\"\"\n",
    "        l1_out = self.l1.predict(x_test)\n",
    "        l2_out = self.l2.predict(x_test)\n",
    "        l3_out = self.l3.predict(x_test)\n",
    "        final_out = (l1_out+l2_out+l3_out)/3\n",
    "        return final_out\"\"\"\n",
    "\n",
    "        result_out = []\n",
    "        for i in range(self.count):\n",
    "            out = self.lr_object[i].predict(x_test)\n",
    "            result_out.append(out)\n",
    "        result_sum = 0\n",
    "        for i in range(self.count):\n",
    "            result_sum = result_sum+result_out[i]\n",
    "        \n",
    "        final_result = result_sum/(self.count)\n",
    "        return final_result\n",
    "\n",
    "\n",
    "class Train_test_split:\n",
    "    def __init__(self,dataset,test_size=0.2,random=1,target='target'):\n",
    "        self.target = target\n",
    "        self.random_state=random\n",
    "        self.test_size=test_size\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        self.row = self.dataset.shape[0]\n",
    "\n",
    "\n",
    "    def split(self):\n",
    "        \n",
    "        np.random.seed(self.random_state)\n",
    "        row_count = int(self.row*self.test_size)\n",
    "        value = np.arange(0,self.row)\n",
    "        row_no = np.random.choice(value,replace=False,size=row_count)\n",
    "        \n",
    "\n",
    "        test_dataset = self.dataset.iloc[row_no]\n",
    "        x_test = test_dataset.drop(columns=[self.target])\n",
    "        y_test = test_dataset[self.target]\n",
    "\n",
    "        remaining_row=[]\n",
    "        for i in range(self.row):\n",
    "            if i not in row_no:\n",
    "                remaining_row.append(i)\n",
    "        train_dataset = self.dataset.iloc[remaining_row]\n",
    "        x_train = train_dataset.drop(columns=[self.target])\n",
    "        y_train = train_dataset[self.target]\n",
    "        \n",
    "        return x_train,x_test,y_train,y_test\n",
    "def r2_score(y_pre,y_test):\n",
    "        \n",
    "    y_mean = np.mean(y_test)\n",
    "\n",
    "    ss_r = np.sum((y_test - y_pre)**2)\n",
    "    ss_m = np.sum((y_test - y_mean)**2)\n",
    "        \n",
    "    r2 = 1-ss_r/ss_m\n",
    "\n",
    "    return r2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc4a0dd-ea0c-4711-97ba-61116801c630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4314be73-4d72-47e4-b38e-659d27ba4087",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('poly_train_new_dataset.csv')\n",
    "target = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7513d2f-3875-4feb-aeb3-5685d1fe9878",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Scaler()\n",
    "s.scale(data.iloc[:,:])\n",
    "data = s.transform(data.iloc[:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df7eab01-2b0a-483c-86e5-df8b34fb9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Train_test_split(data,target='y')\n",
    "x_train,x_test,y_train,y_test = t.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70d1c2a4-bfc8-4efe-b273-1d697d828a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = Polynomial_Regression(degree=4,num=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "561640a5-1501-46c2-8ffd-628e25dd9066",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04a93e75-bf5b-49e2-8fe4-edcf6276b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_value = poly.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76f7a00d-d646-4fe2-8ca2-1d6849cf959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = r2_score(pre_value,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c95bf2d-6d19-40a3-8975-81b5009248c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9910765390839511)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3f36b22-0416-4004-bcb1-da64cac54986",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"poly_test.csv\")\n",
    "\n",
    "y_test_pred = poly.predict(test_data)\n",
    "\n",
    "y_test_pred = np.asarray(y_test_pred).ravel()\n",
    "\n",
    "submit = pd.DataFrame({\n",
    "    \"id\": np.arange(len(y_test_pred)),\n",
    "    \"y\": y_test_pred\n",
    "})\n",
    "\n",
    "submit.to_csv(\"poly_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3525486d-6944-4b2e-9ad8-94e2f59983cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
